%!TEX root = foo-thesis.tex

\chapter{Einleitung}

\section{Terminologie}

\mediumtodo{Terminologie beenden}

\subsection{Punktwolke}
Eine Punktwolke ist eine Datenstruktur, welche als Menge von Punkten in einem $n$-dimensionalen Raum definiert ist. Zusätzlich zu den Koordinaten, die die Position im Raum beschreiben, werden bei der Erstellung einer Punktwolke häufig noch weitere Attribute wie der Intensitäts- oder Farbwert aufgenommen. Des Weiteren lassen sich über gängige Algorithmen zusätzliche Pro-Punkt -Eigenschaften wie die Oberflächennormale \citep{Mitra.Nguyen-2003} oder ein Krümmungswert \citep{Ho.Gibbins-2009} berechnen. 
Meist werden Punktwolken mit Hilfe von 3D-Laserscannern direkt oder mittels photogrammetrischen Verfahren aus Bildern \citep{Remondino.ElHakim-2006} erzeugt. Je nach verwendetem Verfahren können die resultierenden Punktwolken kleine Objekte, ganze Gebäude, Straßenzüge oder sogar Landschaften als virtuelles Modell abbilden.

\subsection{Laserscanner}
LiDAR-Scanner \cite{Collis-1970} verwenden Laserstrahlen, um eine Umgebung abzutasten. Wenn diese Strahlen auf eine Oberfläche treffen, werden sie reflektiert, was der Scanner registriert und so die Position des Reflexionspunktes ermitteln kann. Es können so aber auch andere Eigenschaften erfasst werden, wie Helligkeit bzw. Reflexionsfähigkeit der abgetasteten Oberfläche (die sogenannte \textit{Intensität}), ihre Farbe oder die von der Oberfläche entsandte Infrarot-Strahlung. Letztere kann beispielsweise zum Klassifizieren von Bäumen von zentraler Bedeutung sein. Der Scanner erfasst die Oberflächen dabei jedoch nicht als Ganzes, sondern lediglich 3D-Punkte, welche in Punktwolken abgespeichert werden. Um später aus diesen Punkten wieder Semantik etwa durch Klassifizierungen zu gewinnen, existieren verschiedene Verfahren und Algorithmen.

\subsection{Photogrammetrie}
Bei der Photogrammetrie \cite{Linder-2009} wird aus 2D-Daten wie Bildern und Videos die räumliche Position von Objekten geschätzt. Dabei stützt man sich vor allem auf das Prinzip der Stereoskopie aus der Biologie. Menschen beispielsweise sind in der Lage die Position von Objekten im Raum zu bestimmen, da diese Objekte leicht versetzt sind in den Blickfeldern ihrer Augen. Die Photogrammetrie nutzt auf gleiche Weise eine Anzahl an versetzt aufgenommenen Bildern, um so die Distanz von Objekten zur Kamera zu bestimmen. Die so gewonnenen 3D-Darstellungen von Objekten werden dann in Punktwolken konvertiert, welche dann wiederum weiterverarbeitet werden können.

\subsection{Mobile-Mapping}
Bei einer Mobile-Mapping Punktwolke wurden die Punktdaten durch ein spezielles Fahrzeug XXX 
% beenden

\subsection{Machine Learning}
Unter Deep Learning versteht man das Anwenden eines lernenden, mehrschichtigen künstlichen neuronalen Netzes auf eine komplexe Problemstellung, welche sich meist nur schwer oder auch gar nicht mit nicht lernenden Algorithmen lösen lässt. Dabei orientiert man sich stark an der Funktionsweise von Nervenzellen im menschlichen Gehirn.
% (Ist ein gerichteter Graph usw … ? Bisschen technische unnötige Infos zum stopfen) beenden

\section{Projektüberblick}

3D-Punktwolken können mit Hilfe von Laserscannern oder photogammetrischen Verfahren mit vergleichsweise geringem Aufwand zeit- und kosteneffizient erzeugt werden. Weiterhin enthalten Punktwolken als häufig bis auf wenige Millimeter genaues Modell der realen Welt viele Informationen wie Position oder Farbe der dargestellten Objekte. Entsprechend kann das Modell, je nach Detailgrad und Verfügbarkeit weiterer Attribute, genutzt werden, um Erkenntnisse über Gegebenheiten der realen Welt zu erlangen. Für die Extraktion dieser Informationen werden allerdings auch geeignete Algorithmen benötigt: Besonders wichtig ist dabei, dass diese Algorithmen effizient sind, um die großen Datenmengen, die Punktwolken in sich tragen, verarbeiten zu können. Es existieren jedoch auch Problemstellungen, welche algorithmisch nur vergleichsweise ineffizient gelöst werden können, weshalb die Verarbeitung von Punktwolken mittels Machine Learning und vor allem Deep Learning immer häufiger Einsatz findet. Für diese Fälle wird allerdings generell leistungsfähige Hardware - insbesondere moderne CPUs, GPUs sowie RAM in ausreichender Menge - und viel Rechenzeit benötigt. Insofern gibt es Anwendungsfälle, die nur dann sinnvoll umgesetzt werden können, wenn der verwendete Algorithmus in ausreichender Form skalierbar ist. \\
Weiterhin sind viele der Algorithmen sehr komplex, um auch verschiedene Arten von Punktwolken mit unterschiedlichen Charakteristika wie ihrer Dichte, aber auch Pro-Punkt-Eigenschaften wie der Intensität und Farbwerten sinnvoll verarbeiten zu können. Dies setzt voraus, dass der Anwender über ein tiefgreifendes Verständnis sowohl vom Aufbau der Punktwolken selbst als auch von verfügbaren Algorithmen und ihren Parametern verfügt. Daraus folgt jedoch, dass Nutzer mit weniger fundiertem Fachwissen nur begrenzte Möglichkeiten haben, Punktwolken vor allem für komplexere Anwendungsfälle gewinnbringend zu nutzen. \\
Dementsprechend soll für diese Problemstellung eine Plattform entwickelt werden, die sowohl die nötige Skalierbarkeit zur Anwendung hochkomplexer Algorithmen und Deep-Learning-Verfahren bietet als auch eine entsprechend hohe Nutzerfreundlichkeit sicherstellt.

\section{Schwerpunkte des Bachelorprojekts}

Im Projektverlauf sind diverse Analyse- und Verarbeitungsverfahren für 3D-Punktwolken sowie eine webbasierte Plattform zur Bündelung dieser und bereits vorhandener Funktionalitäten entstanden. Die einzelnen Schwerpunkte werden im Folgenden kurz vorgestellt.

\subsection{Punktwolken-Fingerprint}

Since massive 3D point clouds easily contain millions of points, elaborate operations on them can be very time consuming. However there are also operations which are not executed per point, but rather generate only one result for the whole point cloud. To reduce the time consumption of such operations, a fingerprint of a point cloud can be computed, which has only a fraction of the size of the original point cloud. This fingerprint is then used for further processing steps instead of the point cloud. There are different possibilities how a fingerprint can be created. In this project the fingerprint consists of a collection of histograms, called PCFP. The PCFP is then used to perform operations like a point cloud classification using a deep neural network or parameter estimation based on parameters of similar point clouds.

\subsection{Modelltraining}

Für eine schnelle und gute Schätzung von Parametern für verschiedene Analysen auf noch ungesehenen Punktwolken benötigen wir ein Set an Parametern und Modellen, die auf bereits vorhandenen Punktwolken aufwendig berechnet oder trainiert werden müssen. Dafür haben wir Mechanismen entwickelt, die geometrische Eigenschaften von Punktwolken extrahieren und daraus mittels Heuristiken Eingabeparameter für beispielsweise eine Bodenerkennung ermitteln können. Daneben haben wir eine genetische Hyperparameteroptimierung für Deep Learning Modelle zur semantischen Segmentierung auf Punktwolken implementiert, damit wir für Punktwolken mit vorannotierten Klassen die besten Trainingsparameter finden und so auf unannotierten Punktwolken optimierte Modelle anwenden können.

\subsection{Straßenzustandserkennung}

Moderne Laserscanner, die auf einem entsprechenden Fahrzeug montiert sind, bieten höchste Präzision und können Straßenzüge millimetergenau erfassen. Damit wird eine automatische Analyse dieser Straßen-Punktwolken motiviert, die auch kleine Schäden wie Schlaglöcher und feine Ausbesserungen wie Flickstellen identifizieren soll. Herausfordernd sind dabei vor allem die hohe Punktdichte und die unregelmäßige Natur solcher Schäden. In diesem Projektteil werden zwei Ansätze getestet und verglichen: ein klassischer Machine-Learning-Ansatz mit der Extraktion manuell definierter Features sowie ein moderner Deep-Learning-Ansatz, der aber ebenfalls direkt auf Punktmengen arbeitet.

\subsection{Webplattform}

Die sinnvolle Analyse und Verarbeitung von 3D-Punktwolken erfordert aktuell häufig komplexe Verarbeitungsprozesse und sehr leistungsstarke Hardware. Durch die während des Projekts entwickelte webbasierte Plattform werden verschiedene Anwendungen in einem einzelnen Projekt gebündelt und um eine hohe Skalierbarkeit mittels Lastenverteilung auf viele Rechner in einem Cluster erweitert. Dies ermöglicht auf der einen Seite eine Vereinfachung der Verarbeitungsprozesse, was die Plattform auch für Nutzer mit weniger fundiertem Fachwissen nutzbar macht, und auf der anderen Seite eine Beschleunigung bei der Verarbeitung vieler 3D-Punktwolken durch die Verteilung der nötigen Berechnungen auf alle verfügbaren Rechner.

\section{Einordnung in den Projektkontext}

Die potenzielle Menge an Anwendungsfällen von Punktwolken ist groß. Entsprechend sollte auch die Webplattform neben ihrer einfachen und intuitiven Bedienung bereits entsprechende nützliche Funktionalität bieten. Abseits von zumindest teilweise ausgereiften Verfahren wie der Bodenerkennung bot sich die Erkennung von Straßenschäden in Punktwolken aus zweierlei Gründen an:
\begin{itemize}
    \item Die Genauigkeit des \textit{Mobile Mapping} von Bodenfahrzeugen erlaubt es - im Gegensatz zu eher groberen Luftscans - grundsätzlich, auch kleinere und feinere Schäden oder sonstige Objekte von Interesse zu identifizieren.
    \item Die Suche nach Straßenschäden durch etwa Straßenbaubehörden ist meist noch immer eine manuelle Aufgabe. Ob die Schäden bei einer Fahrt durch die Stadt durch bloßen Blick gesichtet werden oder bei Ansehen von aufgenommenen Videos der Fahrbahnoberfläche: Solche Methoden sind personal- und zeitaufwändig und naturgemäß trotzdem fehleranfällig.
\end{itemize}
Diese Anwendung kann also für einige Nutzer der Plattform sinnvoll sein. Entsprechend wurde sie darin integriert und kann durch eine einfache Bestätigung gestartet werden. Wie bei anderen Aktionen auf Punktwolken werden auch in diesem Fall die notwendigen Schritte gestartet und, wo immer möglich, verteilt auf verschiedenen Rechnern ausgeführt.

\section{Struktur der Arbeit}

Die restliche Arbeit gliedert sich wie folgt: In Kapitel 2 werden verwandte Arbeiten vorgestellt, anschließend folgen in Kapitel 3 Erläuterungen zu den Konzepten zur Straßenzustandserkennung. Kapitel 4 behandelt die Implementierung jener Konzepte, während in Kapitel 5 eine Evaluierung der beiden getesteten Ansätze vorgenommen wird. Das abschließende Kapitel 6 stellt ein Fazit zu den Ergebnissen und gibt einen Ausblick auf mögliche Verbesserungen und Erweiterungen.