%!TEX root = foo-thesis.tex

\chapter{Konzepte}

Das Ziel dieser Arbeit ist eine hinreichend genaue und effiziente Erkennung von Straßenschäden in 3D-Punktwolken auf Basis einzelner Punkte. Training und Evaluierung sind auf einer gescannten Asphaltstraße durchgeführt worden. Etwaige Bilder von Punktwolken oder Objekten in diesen entstammen der Trainings- oder Test-Punktwolke, die im Kapitel \textit{Evaluierung} genauer vorgestellt werden. Die grundlegenden Ideen und Techniken hinter den dafür nötigen Verarbeitungsschritten sollen in diesem Kapitel erläutert werden. Dabei wird sowohl auf den eigens konstruierten Ansatz per Feature-Extraction eingegangen als auch auf einen auf Deep Learning fußenden. Auch das beiden Ansätzen gemeine Pre- und Postprocessing wird kurz dargestellt.

\section{Betrachtete Objektklassen}

Entsprechend des Ziels nehmen Objekte, die auf einen mangelhaften Straßenzustand hinweisen, den vornehmlichen Fokus ein. Einfluss auf die Entstehung von Schäden verschiedener Art haben unter anderem der Niederschlag, temperaturbedingte Verformungen sowie die Verkehrsbelastung selbst.\footnote{https://www.ise.kit.edu/rd\_download/SBT/Kolloquium\_SBT\_2011-11-23\_C.Karcher.pdf} Es existieren Leitfäden\footnote{https://itzeb.heller-ig.de/leitfaden/} zur empfohlenen Auswertung solcher \textit{Substanzmerkmale}, an denen sich unter anderem bzgl. der verschiedenen Klassen orientiert wurde. Diese Klassen sind zum besseren Verständnis als Bilder der Punktwolke in Abbildung X dargestellt. \mediumtodo{Was anderes als Fußnoten nutzen?}\\
Darunter fallen insbesondere merkliche Absenkungen wie Schlaglöcher oder Risse. Schlaglöcher zeichnen sich durch lokale Höhenunterschiede, welche von mehreren Millimetern bis hin zu einigen Zentimetern reichen können, sowie ihre meist eher rundliche Form aus. Solche Absenkungen stellen gerade bei höheren Geschwindigkeiten und entsprechender Tiefe eine erhebliche Gefahr für die Kontrolle des Fahrzeugs und somit ein potenzielles Unfallrisiko dar. \\
% Unterschieden wird dabei zwischen \textit{aufgelegten} und \textit{eingelegten} Flickstellen, die auf die bestehende Fahrbahnoberfläche aufgebracht werden bzw. in die jeweils entnommene Decke wieder hineingelegt werden.
Auch Flickstellen bilden eine interessante Klasse: Sie werden angebracht, um beschädigte Straßenteile - wie zum Beispiel ein Schlagloch - zu überdecken und auf diese Weise ungefährlich zu machen. Charakterisiert werden sie durch ihre wegen der maschinellen Fertigung meist rechteckige Struktur sowie der im Vergleich zur unmittelbaren Umgebung oft dunkler erscheinenden Fugendichtmasse. Letztere kann durch Überquellen ebenfalls für marginale Höhenunterschiede sorgen. Auch wenn Flickstellen selbst also keinen Schaden darstellen, ist ein Straßenabschnitt, der zu großen Teilen von Flickstellen überzogen ist, ein möglicher Hinweis auf eine sinnvolle Komplettreparatur. \\
Gullys und Kanaldeckel kommen in vielen Ausprägungen bezüglich Größe und Form daher. Obwohl diese selbstverständlich begründet angelegt wurden, zeichnen auch sie sich durch charakteristische Höhenunterschiede aus, was einen Vergleich unter anderem mit Schlaglöchern und somit eine genauere Betrachtung wert ist. Ein zuverlässiges Erkennen von Gullys kann außerdem, wie im Unterabschnitt \textit{Uniqueness} sowie im Kapitel \textit{Fazit und Ausblick} erwähnt wird, einen weiteren Vorteil bringen: Aufgrund ihrer beständigen Struktur können mehrere Scans desselben Straßenabschnitts zueinander ausgerichtet werden. Damit könnte etwa die Veränderung des Straßenzustands in einem bestimmten Zeitraum dokumentiert werden. \\
Eine weitere Auffälligkeit sind besonders dunkle, unregelmäßige und teils sehr große Flecken. Ohne genauen Anblick vor Ort ist nicht zweifelsfrei auszumachen, worum es sich handelt: Bindemittelaustritte sind eine Alternative, aber auch Ölflecken sind möglich und, durch die Nähe zu Parkplätzen, hier auch plausibel. Frische Ölflecken allerdings stellen augrund der geringen Griffigkeit eine große Rutschgefahr dar. Wegen dieser Option werden auch jene Stellen gesondert behandelt; der Einfachheit halber ist in der Arbeit folgend die Rede von Ölflecken. \\
Von der entgegengesetzten Intensität, aber für den sicheren Straßenverkehr unerlässlich, sind Fahrbahnmarkierungen. Durch ihre Materialzusammensetzung sollen sie sich zu allen Tageszeiten und Wetterbedingungen stark abheben vom Rest der Fahrbahn und so Orientierung bieten. Von Interesse könnte hier insbesondere sein, ob und welche Markierungen sich stellenweise durch Verschleiß nicht mehr ihrem Zweck gemäß genug abheben und einer Auffrischung oder Erneuerung bedürfen. \\\\
Andere Arbeiten wie \cite{Zhiqiang.etal-2019} und \cite{Famili.etal-2021} haben sich vollständig auf Höhenunterschiede vielfältiger Art konzentriert. Dazu zählen nicht nur Schlaglöcher, sondern auch feine Risse, Spurrillen oder Unebenheiten der Straße auf Quer- und Längsseite um wenige Prozent, die unter Umständen über mehrere Meter gemessen werden. Dies waren keine Ziele der Arbeit, entweder aus Mangel an geeigneten und ausreichenden Daten oder, da andere Verfahren besser geeignet erscheinen. Für die Berechnung dieser Quer- wie Längsunebenheit beispielsweise existieren Empfehlungen der * \mediumtodo{hier vllt. was von der Stadt Essen}. Diese beschreiben imaginäre Holzlatten, welche in regelmäßigen Abständen quer zur und längs der ebenfalls gescannten Straße gelegt werden. Anhand der Höhendifferenzen der Lattenenden können die gesuchten Werte mathematisch präzise ermittelt werden, ebenso andere Kenngrößen wie die Spurrinnentiefe oder fiktive Wassertiefe. \cite{Famili.etal-2021} verfolgen ähnliche Ansätze über Funktionsgraphen von Querschnitten der Oberfläche. Solche geometrischen Verfahren sind bereits verhältnismäßig akkurat und zuverlässig. \\ 
Die Schäden dieser Art spielen auch eine Rolle bei der Straßenzustandsbewertung. Daher könnten jene Verfahren kombiniert werden mit Ansätzen, die für die Erkennung von unregelmäßigen Schäden der Fahrbahnoberfläche spezialisiert sind, wie es die in dieser Arbeit getesteten sein sollen. Auf diese Weise kann erst ein gesamtheitliches Bild des Straßenzustands geschaffen werden.

\section{Preprocessing}

Die Schadenserkennung wird nicht unmittelbar auf der ursprünglich eingehenden Punktwolke (nachfolgend \textit{Input}) ausgeführt, sondern zuerst auf geeignete Weise vorprozessiert.
Die erste Aufgabe besteht darin, den Boden des Inputs zu bestimmen, um die Menge der potenziell interessanten Punkte für diesen Anwendungsfall zu reduzieren. Dazu wird eine Bodenerkennung (\textit{Ground Detection}) eingesetzt, welche unter anderem mit Höhenmodellen arbeitet. Schließlich werden die als Boden erkannten Punkte mit der entsprechenden semantischen Klasse markiert. In der Pipeline dieser Arbeit wird eine Ground Detection eingesetzt, die für den jeweiligen Input optimierte Parameter nutzt. Diese werden im Voraus - als anderes Teilsystem des Projekts - ermittelt anhand der Oberflächeneigenschaften des Inputs. Dadurch soll möglichst der komplette Boden, also insbesondere die vollständige Straße, und möglichst wenig an restlichen Punkten erfasst werden. \\\\
Mit diesen Informationen geht es dann an den Schritt, der die Straße selbst erkennen soll. Diese Street Detection soll also außenstehenden Rasen, niedrige Häuserwände und sonstige als Boden klassifizierte, aber nicht zur Fahrbahn selbst gehörenden Bereiche (\textit{Noise}) entfernen. Dabei wird vor allem mit der relativen Dichte der Punkte und einer darauf basierenden Abschätzung der Trajektorie des Scannerfahrzeugs gearbeitet. Dies beruht auf der Annahme, dass durch die Arbeitsweise der Scanner nahegelegene Oberflächen deutlich dichter abgetastet werden als weiter entfernte. Die Street Extraction baut auf einer zumindest größtenteils gelungenen Ground Detection auf. Sobald die nun als Straße erkannten Punkte extrahiert sind, beginnt der jeweilige Ansatz auf seine Weise, die oben genannten Klassen in der verbliebenen Punktwolke zu erkennen. \\\\
Zunächst erfolgt jedoch noch eine Wertenormalisierung. Während der Deep-Learning-Ansatz seine eigene Art der Normalisierung vornimmt, geht der Feature-Ansatz folgendermaßen vor: Das Intensitätsattribut besitzt eine hohe Varianz bezüglich verschiedener Laserscanner, die unter anderem von deren unterschiedlicher Technik oder Verarbeitung verursacht wird. Zwar liegt der Wertebereich des Attributs grundsätzlich bei 0 bis 65535, wird aber oftmals nicht ausgenutzt. Der Intensitätswert desselben Punktes, aufgenommen von zwei verschiedenen Scannern, kann sich um mehrere Tausend unterscheiden. Aus diesem Grund werden diese absoluten Werte zunächst in relative umgewandelt, sodass sie über verschiedene Punktwolken hinweg vergleichbar sind. \\
Ein weiterer Aspekt, der sich negativ auf die Normalisierung auswirken kann, sind einzelne Punkte, deren Intensität übermäßig stark von der Mehrheit der anderen Werte abweicht. Unabhängig davon, ob dies Messungenauigkeiten sind oder tatsächlich einzelne Abweichler, ist ein Entfernen dieser Werte erstrebenswert. Da aber natürlich auch diese Punkte erhalten bleiben und eine Intensität besitzen sollen, werden diese Außenseiter-Punkte noch vor der Normalisierung bestimmt und ihre Intensität auf den niedrigsten bzw. höchsten Wert gesetzt, der nicht zu den abweichenden Werten gezählt wird. Auf diese Weise sollen die Relationen zwischen verschiedenen Punktwolken erhalten bleiben, ohne durch die Werteanpassung und -normalisierung einen merklichen Informationsverlust zu erleiden bzgl. der hier betrachteten Klassen. \\
Da bei den 3D-Koordinaten keine so erheblichen Unterschiede zu erwarten sind, werden diese Werte nicht normalisiert und alle letztlich daraus ermittelten Features als vergleichbar über verschiedene Punktwolken hinweg angesehen.

\section{Ansatz Feature-Extraction}

Der Ansatz über die Feature-Extraction in seiner momentanen Form gliedert sich grob in zwei Teilschritte: Zunächst erfolgt die Ermittlung der Pro-Punkt-Features selbst, was den deutlich zeitintensiveren Anteil ausmacht. Anschließend erfolgt die Vorhersage (\textit{Prediction}) der Klassen allein auf Basis dieser berechneten Featurevektoren über einen Random Forest, ggf. reduziert auf eine Menge von in diesen Werten besonders auffälligen Punkten (siehe Abschnitt \textit{Uniqueness}). Dieses Vorgehen entspricht somit dem klassischen Machine-Learning-Prozess.

\subsection{Features}

Bei einer manuellen Feature-Bestimmung stellt sich zuerst die Frage, welche Features überhaupt in Betracht gezogen werden. Daher sollen nun grundsätzliche Features erläutert werden, die gewisse Unterscheidungsmerkmale zwischen den verschiedenen Klassen ausdrücken. \\
Die reine Intensität, also ein Maß zur Ermittlung der Stärke des reflektierten Lasers \mediumtodo{Paper?}, hebt bereits Fahrbahnmarkierungen durch einen sehr hohen und Ölflecken durch einen sehr niedrigen Wert hervor. \cite{Zhiqiang.etal-2019} nutzen dieses Attribut ebenfalls als Teil ihrer Featurevektoren, wobei dort noch eine Interpolation über Gewichtungen invers zur Distanz vorgenommen wird. Da der eine Wert scale-unabhängig ist und es auch einzelne Punkte mit diesen extremen Ausschlägen gibt (siehe Abbildung Y), die weder zur einen noch zur anderen Klasse gehören, wird an dieser Stelle eine Abhängigkeit vom Scale geschaffen: Beispielsweise kann der Durchschnitt der Nachbarschaftsintensitäten berechnet werden. Im kleinen Scale mögen diese Werte sich auch für Ausreißerstellen ähneln, im größeren Scale aber gleicht sich das für diese aus und bleibt etwa für Fahrbahnmarkierungen charakteristisch hoch. \\
Ebenfalls auf dem Intensitätsattribut beruhend ist eine Betrachtung der lokalen Intensitätsunterschiede der Nachbarn zum jeweils betrachteten Punkt. Neben Fahrbahnmarkierungen und Ölflecken sind gerade Flickstellen dadurch gekennzeichnet, dass die deutlich dunklere Fugendichtmasse, die Streifen mit wenigen Zentimetern Breite bildet, sich abhebt vom Rest der umliegenden Oberfläche und somit die meist rechteckige Form erkennen lässt. Auch Schlaglöcher besitzen oft, bedingt durch den bei ihnen abgetragenen Asphalt, eine geringere Intensität. Diese Differenzen sollen also dabei helfen, in ihrer Intensität auffällige Stellen einzugrenzen und zu erkennen. \\\\
% später evtl. noch reine Nachbarintensities dazunehmen sowie Elevation Differences / Roughness Index / Principal bzw. Gaussian Curvature
Neben diesen in unterschiedlichen Formen auf der Intensität basierenden Features werden natürlich auch die 3D-Koordinaten der Punkte genutzt. Es existieren verschiedene Maße, die für einen einzelnen Punkt die Form und Oberfläche seiner lokalen Nachbarschaft beschreiben. Eine Auswahl dieser grundsätzlich einwertigen Features soll im Folgenden erläutert werden. \\
Die Basis jener Maße ist die Betrachtung der umgebenden Koordinaten eines Punktes und deren Verteilung. Dies wird repräsentiert durch die Kovarianzmatrix. Grundsätzlich beschreibt die Kovarianz zwischen zwei Variablen einen Grad ihres linearen Zusammenhangs: Ihr Vorzeichen deutet an, ob höhere Werte der einen Variable eher mit höheren oder niedrigeren Werten der anderen Variable einhergehen und umgekehrt. Im konkreten Fall von 3D-Daten sind die Variablen die drei Dimensionen \textit{X}, \textit{Y} und \textit{Z} selbst, die zusammen eine 3×3-Kovarianzmatrix einer Punktmenge bilden, welche in den entsprechenden Einträgen die jeweilige Kovarianz zwischen den Dimensionen beschreibt. Die Durchschnitte der Variablen für die Zentrierung der Koordinaten sind in diesem Fall die Koordinaten des durchschnittlichen Punkts der Menge, dem sogenannten \textit{Centroid}. \\\\
Ist diese Matrix für einen Punkt und seine Nachbarschaft einmal berechnet, müssen nun sinnvolle Informationen daraus extrahiert werden. Für die genutzten Maße geschieht das mittels der drei Eigenwerte der Matrix. Diese bemessen die höchsten Varianzen entlang paarweise orthogonaler Achsen. Der zum geringsten Eigenwert zugehörige Eigenvektor repräsentiert dabei die Normale zur Punktmenge, welche senkrecht auf deren approximierter Oberfläche steht. \\
Diese Eigenwerte $\lambda_1$, $\lambda_2$ und $\lambda_3$ werden absteigend sortiert, sodass $\lambda_1 \geq \lambda_2 \geq \lambda_3$. Anschließend werden sie normalisiert durch Division ihrer Gesamtsumme: 
\begin{equation}
e_i = \frac{\lambda_i}{\lambda_1 + \lambda_2 + \lambda_3}, i \in \{1, 2, 3\}.
\end{equation}
Mittels dieser drei Werte können nun die gesuchten Maße \textit{Linearity}, \textit{Planarity}, \textit{Scattering} (auch \textit{Spherity}) sowie \textit{Local Curvature} (auch \textit{Change of Curvature}, folgend nur \textit{Curvature}) einfach berechnet werden, wie es in Tabelle \ref{table:eigenvalue_features} dargestellt ist. Diese Features werden unter anderem von \cite{Zaboli.etal-2019} genutzt, um städtische Objekte von Mobile-Mapping-Punktwolken zu erkennen. Sie beschreiben, grob formuliert, wie linear, eben oder rund die Nachbarschaft eines Punktes sich verhält und wie stark sie sich im Vergleich zu einer Ebene krümmt. Von ihrer Aussagekraft sind sie vergleichbar mit den in \cite{Zhiqiang.etal-2019} genutzten Features \textit{Roughness Index} und \textit{Gaussian Curvature}. Im Gegensatz dazu werden in diesem Ansatz aber keine globalen Features verwendet, die jeweils die gesamte Punktwolke verarbeiten. Während etwa \cite{Zhiqiang.etal-2019} \textit{Triangulated Irregular Networks} und Verfahren der \textit{Object Segmentation} dazu nutzen, um die Umrisse von Objekten wie Schlaglöchern und Rissen zu detektieren, sollen hier tatsächlich nur lokale, also jeweils auf einen Scale beschränkte, Features genutzt werden.

\begin{table}
\centering
\begin{tabular}{c|c|c|c}
Linearity & Planarity & Scattering & Curvature \\ 
$\frac{e_1 - e_2}{e_1}$ & $\frac{e_2 - e_3}{e_1}$ & $\frac{e_3}{e_1}$ & $\frac{e_3}{e_1 + e_2 + e_3}$ \\
\end{tabular}
\caption{Die vier einwertigen, auf den Eigenwerten der Kovarianzmatrix basierenden Features zur Beschreibung der Form der lokalen Nachbarschaft.}
\label{table:eigenvalue_features}
\end{table}

\subsection{Scales}

Um einen Punkt zu charakterisieren, wird seine lokale Nachbarschaft betrachtet. Für die Ermittlung der Nachbarschaft gibt es grundsätzlich zwei Wege: die \textit{k} nächsten Nachbarn zu nehmen oder alle Nachbarn, die im vorgegebenen Radius einer Kugel um den Ursprungspunkt liegen. Der Vorteil an den k Nachbarn ist, dass man sich über die betrachtete Nachbarzahl sicher sein kann. Allerdings hängt der dabei betrachtete Radius erheblich von der lokalen Punktdichte ab: Beim Mobile-Mapping wird für Punkte auf der Trajektorie des Scannerfahrzeugs mit demselben k also ein deutlich geringerer Radius betrachtet als für Punkte näher am Rand, siehe Abbildung X. Deshalb eignet sich die Radiusbetrachtung besser für konsistente und über verschiedene Punkte vergleichbare geometrische Features \citep{Thomas.etal-2018}. Diese Art der Nachbarschaftsbetrachtung - von nun an werden die Radii \textit{Scales} genannt - findet in dem Ansatz entsprechend Verwendung. \\\\
Die nächste Frage ist, welche konkreten Scales genutzt werden. Dass überhaupt die Nutzung mehrerer Scales sinnvoll ist, zeigt sich beim Blick auf verschiedene Objekte, die es zu erkennen gilt. Zum einen sind natürlich gerade Schlaglöcher besonders unregelmäßige Strukturen, die in vielerlei Ausprägungen vorkommen können: über mehrere Größen hinweg sowie Formen von sehr rund bis eher länglich. Flickstellen zeichnen sich vorzugsweise in kleinem Scale aus durch ihre hohen Intensitätsunterschiede. Bei größeren Gullys wird der innere, mittige Bereich aber erst mit deutlich größerem Radius auffällig, denn im kleinen Bereich ist dieser sehr planar. Um mit diesen verschiedenen Granularitäten umgehen zu können, werden mehrere, an typische Objektgrößen angepasste, Scales genutzt.
% hier Bild der eingefärbten Nachbarn nach kNN und nach Scale

\subsection{Ein- und mehrwertige Features}

Als Features für Punkte kommen zum einen einwertige Daten in Betracht. Das können direkt Attribute sein wie die Intensität, Werte, die sich aus der Punktenachbarschaft ergeben wie Curvature, oder kumulierte Formen davon wie Durchschnitte oder Standardabweichungen. \\
Daneben gibt es auch die Möglichkeit für mehrwertige Features. Diese können etwa als Histogramme ausgedrückt werden, also Häufigkeitsverteilungen für bestimmte numerische Merkmale. Sie sind zusammengesetzt aus mehreren sogenannten Bins, welche die Anzahl der Observationen zählen, die in den von ihnen aufgespannten Wertebereich fallen. In dieser Arbeit entspricht eine Observation dem Merkmal eines Punktes, etwa einem Curvature-Wert. Histogramme können linear sein, wenn alle Bins einen identisch großen Wertebereich haben, oder entsprechend nicht-linear, wobei in diesem Ansatz nur von linearen Histogrammen Gebrauch gemacht wurde, wie im Kapitel \textit{Implementierung} nachzuvollziehen ist. \\\\
Der Vorteil der Histogramme besteht in einer grundsätzlich höheren Aussagekraft durch die genauere Charakterisierung der Nachbarschaft \citep{Rusu.etal-2008}: Was sich etwa in einem Durchschnittswert durch entgegengesetzte Größen aufheben würde, kann nun präziser dargestellt werden. Mehr und damit feinere Bins, d.h. jeweils kleinere Wertebereiche, haben eine potenziell höhere Aussagekraft. Allerdings resultiert dies unter Umständen in einer zu starken Verteilung der Häufigkeiten, sodass charakteristische Ausschläge verloren gehen. Histogramme bieten aber noch weitere Vorteile: Die oben angesprochenen teilweise erheblichen Unterschiede der Dichte an verschiedenen Stellen einer Mobile-Mapping-Punktwolke machen einwertige Features unter Umständen schwierig vergleichbar für einen festen Scale. Bei Histogrammen kann dieser Fakt abgeschwächt werden, da durch das Einsortieren in Bins die Werte normalisiert werden in den Bereich von 0 bis 1, und zwar unabhängig von der Anzahl der Nachbarn. Deswegen werden im Ansatz zum Vergleich zwischen Histogrammen und auch für die Prediction lediglich die relativen Bingrößen (\textit{Frequencies}) betrachtet. Ferner wird auch der Umgang mit Außenseiterpunkten (\textit{Outliern}), die teilweise von Messungenauigkeiten stammen, erleichtert: Während sie im einwertigen Fall ein Feature stark verzerren können, erhöhen sie beim Histogramm nur die Frequency eines Bins leicht und sind somit beinahe wie leere Bins zu behandeln. Ähnliches gilt für Werte mit hoher Varianz, wie es vor allem die gemessene Intensität ist. Schließlich sind die Histogramme, im Gegensatz zu einigen anderen lokalen Deskriptoren \citep{Han.etal-2018}, unabhängig von Transformationen der Punktwolke wie Rotation oder Translation. \\
Für diesen Ansatz werden Histogramme genutzt bei den Features zur geometrischen Oberflächenbeschreibung sowie den Intensitätsunterschieden. In den Kapiteln \textit{Implementierung} und \textit{Evaluierung} wird darauf eingegangen, mit welchen Wertebereichen und Binzahlen gearbeitet wird bzw. was dies für Auswirkungen hat auf die Unterscheidbarkeit zwischen den Klassen. Grundsätzlich wird aber eine Kombination aus ein- und mehrwertigen Features eingesetzt. Zusammengehörige einwertige Features sowie einzelne Histogramme eines Attributs werden künftig teilweise als \textit{Featureräume} bezeichnet, etwa als Curvature-Featureraum.

\subsection{Uniqueness}

Die zu klassifizierenden Objekte und deren einzelne Punkte sollten sich - im ein oder anderen Featureraum - merklich unterscheiden von den gewöhnlichen Straßenpunkten, die weder einen Schaden noch ein sonstiges besonderes Objekt darstellen. Dieses Konzept der \textit{uniquen} Punkte, teilweise auch \textit{key feature points}, hat das Ziel eine Punktwolke durch eine geeignete und angemessen große Menge von Punkten zu charakterisieren. \\
Die Basis für die Ermittlung dieser uniquen Punkte sind, wie vom Prinzip her auch in \cite{Rusu.etal-2008} genutzt, die Berechnung einer Featurerepräsentation des \textit{durchschnittlichen} Punktes (\textit{Mean}) sowie der Distanz der Repräsentation einzelner Punkte zu diesem Durchschnitt. Diejenigen Punkte, die eine spezifizierte ausreichend große Distanz besitzen, werden als unique betrachtet. \\
Die durchschnittliche Repräsentation kann für einwertige Featureräume durch einfaches Bilden des Durchschnitts ermittelt werden, für mehrwertige Featureräume (Histogramme) werden die jeweiligen Bins über alle Punkte aufsummiert und entsprechend die Frequencies neu berechnet. Die Distanz von der Punktrepräsentation zur Meanrepräsentation kann dann über ein geeignetes Distanzmaß berechnet werden. Bei Betrachtung aller Distanzen können anschließend die entferntesten Punkte bestimmt werden. \\\\
Die Gründe für eine solche Darstellung der Punktwolke durch eine geringere Zahl an Punkten sind vielfältig. Eine Motivation kann - gerade für Objekte, für die eher nicht erwartet wird, sich zu verändern oder zu bewegen - die Registration sein. Dabei sind die Ausgangslage zwei oder mehr Punktwolken, die durch mehrere Scans entstanden sind, etwa zu verschiedenen Zeitpunkten oder aus unterschiedlichen Perspektiven. Durch geeignete Algorithmen wie dem \textit{Sample Consensus Initial Alignment} \citep{Rusu.etal-2009} können für unique Punkte des einen Scans sogenannte Korrespondenz-Punkte im anderen Scan gesucht werden, welche die jeweils ähnlichste Featurerepräsentation besitzen. Aus diesen Paaren kann die nötige Transformation zwischen den Punktwolken bestimmt und durchgeführt werden. Durch ein entsprechendes Fehlermaß, etwa über die paarweisen Distanzen, kann die Qualität dieser Annäherung ermittelt und nach dem geringsten Fehler optimiert werden, bevor eine abschließende Verfeinerung dieses \textit{Alignments} zum Beispiel über nicht-lineare Verfahren erfolgt. Der Vorteil der Nutzung von uniquen Punkten liegt hierbei darin, dass die Ausgangsmenge der zu betrachtenden Punkte für die Korrespondenzsuche drastisch, aber zugleich sinnvoll reduziert wird. Die tiefgreifendere Verwendung des Uniqueness-Konzepts wird in dieser Arbeit nicht näher behandelt, doch im Kapitel \textit{Fazit und Ausblick} wird noch einmal angerissen, inwiefern damit potenziell Änderungen des Straßenzustands im Verlaufe der Zeit ermittelt werden könnten. \\
Ein zweiter und pragmatischer Grund für die Ermittlung von uniquen Punkten ist die resultierende Datenreduktion. Wie im Kapitel \textit{Implementierung} genauer erläutert wird, ist in der momentanen Architektur dieses Ansatzes eine Übertragung der Featurevektoren mit temporärer Festplattenspeicherung nötig. Da weiterhin die Nutzung von mehrwertigen Features wie Histogrammen inhärent zusätzlichen Speicheraufwand bedeutet, soll das Uniqueness-Konzept Abhilfe schaffen. Eine Bedingung für ordentliche Ergebnisse der Uniqueness ist in diesem Anwendungsfall, dass die Objekte von Interesse eine kleine Minderheit der Punkte repräsentieren und so in der Gesamtpunktwolke entsprechend auffallen. Dies ist bei gewöhnlichen Straßenpunktwolken der Fall, siehe Kapitel \textit{Evaluierung} für Relationen der Klassen. Für die nicht-uniquen Punkte wird die implizite Annahme getroffen, dass diese den gewöhnlichen Straßenzustand repräsentieren und ihnen somit direkt die Klasse \textit{Straße} zugewiesen wird.

\subsection{Approximation für größere Scales} 

Die Zahl der Nachbarn eines Punktes erhöht sich mit linear steigendem Scale deutlich stärker als linear. Entsprechend verlängert sich auch die Prozessierungsdauer pro Scale erheblich. Da unter Umständen solche größeren Scales aber nicht einfach ausgelassen werden können, beinhaltet der Feature-Ansatz die Möglichkeit einer Approximation der Featurevektoren aus reduzierten Originaldaten. \\
Dazu wird, noch vor der Extraktion der Features, eine Dichtereduktion (\textit{Density Reduction}) ausgeführt. Diese Operation kann die Punktemenge senken, indem alle Punkte etwa innerhalb eines Würfels zu einem einzigen Punkt zusammengefasst werden. Für Feinheiten sind kleinere Scales gedacht, die jeden Punkt berücksichtigen. Groberen Betrachtungen genügt auch eine regelmäßig gesampelte Teilmenge aller Punkte. \\
Die Density Reduction verringert die Nachbarzahl jedes Punktes und somit insbesondere die Dauer der Featuregewinnung. Allerdings sind anschließend nur Features berechnet worden für eine Teilmenge der ursprünglichen Punkte. Da aber für jeden Punkt ein vollständiger Featurevektor erwartet wird für die letztliche Prediction, muss dieser jeweils aus den bisher ermittelten approximiert werden. Dazu werden für jeden Originalpunkt und pro Scale alle reduzierten Punkte in kleiner Nachbarschaft gesammelt, ihre Featurevektoren gewichtet nach der inversen Distanz zum Originalpunkt und so zu einem einzelnen Featurevektor verrechnet. Dieser Approximationsschritt soll also die Prozessierungszeit senken und die einzelnen Featurevektoren dabei trotzdem hinreichend genau darstellen.

\subsection{Prediction per Random Forest}

Anhand der zuvor ermittelten Featurevektoren, bestehend aus mehreren Scales und ggf. reduziert auf die Menge der uniquen Punkte, soll nun jeweils die Klasse jedes Punktes bestimmt werden. Wie bei \cite{Zhiqiang.etal-2019} wird im Feature-Ansatz dafür ein Random Forest verwendet, der in dortigen Experimenten einen probabilistischen Ansatz sowie ein Support-Vector-Machine-Modell übertroffen hat. Ein Random Forest zeichnet sich grundsätzlich durch eine hohe Robustheit gegenüber kleinen Abweichungen oder Anomalien aus, die besonders bei feinen Features, wie sie hier vorkommen, wünschenswert ist. \\
Die Grundlage eines Random Forest ist der Decision Tree. Ein solcher einzelner Baum ist steuerbar über eine Menge von Parametern. Im Allgemeinen erhält er nur eine Teilmenge der Trainingsdaten und auch nur eine Teilmenge der Features zur Betrachtung. Anschließend wird er daraufhin trainiert, durch eine Reihe von Entscheidungen - im rein numerischen Fall basierend auf geeigneten Schwellwerten - die Klasse des Inputs anhand der ihm zur Verfügung gestellten Features zu bestimmen. Um \textit{Overfitting}, also eine zu starke Spezialisierung auf die Trainingsdaten und damit zu geringe Generalisierung, zu vermindern, kann auch die maximale Anzahl an Entscheidungen (die Tiefe des Baums) festgelegt werden. \\
Für sich genommen ist ein einzelner Baum nur bei einigen Features zu einer sinnvollen Entscheidung für eine Klasse geeignet, bei anderen Features ist diese eher zufällig. Dies wird im Random Forest dadurch ausgenutzt, dass jener aus teils Hundert oder mehr unkorrelierten Decision Trees besteht. Jeder von diesen gibt seine Entscheidung preis, und die endgültige Entscheidung des gesamten Modells ergibt sich als Mehrheitsmeinung (\textit{Majority Vote}) dieser Einzelvorhersagen. Dieses Zusammenspiel aus ``Expertenmeinungen`` jeweils spezialisierter Bäume und eher zufälligen Entscheidungen der restlichen Bäume ist eine der wesentlichen Gründe für die Stabilität dieser Modellart. \\
Genaueres zum genutzten System und den verwendeten Random-Forest-Parametern finden sich im entsprechenden Abschnitt des Kapitels \textit{Implementierung}.

\section{Ansatz Deep Learning}

\textit{PointNet} \citep{Charles.etal-2017} ist eine 2016 erstmals vorgestellte Deep-Learning-Architektur. Das neuronale Netz ist in der Lage eine Punktmenge zu verarbeiten, ohne von der Reihenfolge der Punkte abhängig zu sein. Dabei kann es sowohl einer gesamten Punktwolke eine Klasse zuweisen als auch die Punktwolke nach semantischen Klassen pro Punkt segmentieren. Die Fähigkeit mit der inhärenten Unstrukturiertheit von Punktwolken direkt umzugehen, machte PointNet so neuartig. Verwandte Arbeiten zuvor basierten, wie schon gleichnamigen Kapitel aufgeführt, häufig auf einer Einteilung der Punktwolke in ein regelmäßiges 2D- oder 3D-Gatter oder eine Menge von Bildern, um etablierte bildbasierte Verfahren oder \textit{Convolutional Neural Networks} einzusetzen.
Da der Fokus dieser Arbeit nicht eine Implementierung von PointNet war, soll dessen Architektur nur grob zusammengefasst werden. Als wichtige Merkmale des Netzes werden genannt: 
\begin{itemize}
    \item das Nutzen einer symmetrischen Funktion für die permutationsunabhängige Prozessierung der Punkte
    \item die gleichzeitige interne Verwendung und Konkatenation von globalen Features und lokalen Features für die Berechnung der Gesamtklasse der Punktwolke oder der Einzelklassen der Punkte
    \item die automatische Angleichung der Koordinaten sowie Pro-Punkt-Features über Punktwolken hinweg, um eine Unabhängigkeit von Transformationen wie Rotation und Translation zu erreichen
\end{itemize}
Standardmäßig besteht der Input für PointNet lediglich aus den dreidimensionalen Punktkoordinaten. Allerdings lassen sich beliebige weitere Pro-Punkt-Features anhängen, was insbesondere für solche Attribute sinnvoll ist, die sich nicht indirekt aus den Koordinaten allein herleiten lassen. In dieser Arbeit gilt das für die Intensität, die auch im Feature-Extraction-Ansatz genutzt wird. Entsprechend werden für einen fairen Vergleich diese Werte den Koordinaten angehängt. \\
Auch die Arbeitsweise der beiden Ansätze bei der Prediction unterscheidet sich: Statt sich Punkte einzeln anzuschauen, Features zu berechnen und eine Klasse vorherzusagen, wird bei der Nutzung von PointNet eine (durch Parameter in der Größe beeinflussbare) Menge von Samplepunkten aus der gesamten Punktwolke gezogen. Für jeden dieser Punkte wird eine feste Zahl an Nachbarn gezogen in ebenfalls fest eingestelltem (maximalen) Scale. Bei zu wenig Nachbarn werden Punkte mehrmals in die Menge aufgenommen. Nach Durchlaufen des Netzes wird jedem dieser Punkte auf einmal eine eigene Klasse zugewiesen, die das Modell für am wahrscheinlichsten hält. \\
Bei der Prozessierung ermittelt PointNet weiterhin von sich aus eine Menge sogenannter \textit{Critical Points}, welche die lokale Nachbarschaft hauptsächlich charakterisieren. Dieses Resultat ähnelt damit der Idee des im Feature-Ansatz genutzten Uniqueness-Konzepts. \\ 
% vllt Formulierung ändern, dass nicht direkt berechnet, sondern mit Trick der Autoren ausgegeben werden kann -> bei PCNN ausgeben lassen?
Insgesamt lässt sich sagen, dass sich dieser modernere Ansatz - wie andere Deep-Learning-Architekturen - dadurch auszeichnet, automatisch aussagekräftige Features aus dem Input zu extrahieren. Dadurch wird ein grundsätzlich generischer Ablauf geschaffen, der nicht mehr auf manuell erarbeiteten und meist auf einen Anwendungsfall spezialisierten Features basiert, sondern lediglich ausreichend Trainingsdaten benötigt.

\section{Postprocessing}

Die Nachprozessierung findet statt, nachdem vom jeweiligen Ansatz alle Punkte einer Klasse zugewiesen wurden. Die Grundidee ist, Klassen von denjenigen Punkten noch einmal zu ändern, bei denen eine andere Klasse aufgrund der unmittelbaren Nachbarklassen sehr wahrscheinlich ist. Dies geschieht in zwei Richtungen: \\
Zum einen werden Klassen-Außenseiter als Standardklasse ``Straße`` eingestuft. Das sind Punkte, die momentan nicht ``Straße`` sind, aber nicht genügend Punkte ihrer Klasse in unmittelbarer Umgebung haben. Für jede der betrachteten Objektklassen wird angenommen, aus mehr als einigen wenigen Punkten zu bestehen. Solche Klassifizierungen werden daher als Noise interpretiert und nicht weiter als bemerkenswert behandelt. \\
Die andere Richtung behandelt Straßen-Punkte, die inmitten von Nicht-Straßen-Punkten liegen. Bei genügend großem Anteil von letzterer Gruppe nimmt der Punkt die häufigste Nicht-Straßen-Klasse seiner Nachbarschaft an. Auf diese Weise werden zum Beispiel Schlaglöcher innen aufgefüllt oder die Mitte von Gullys ergänzt, wenn sie etwa wegen eines zu geringen Scales nicht als eben diese Klassen erkannt wurden. \\
Die beiden Schritte werden mit verhältnismäßig vorsichtigen Werten durchgeführt, um die begründeten initialen Klassifizierungen nicht zu stark zu verändern auf Basis einer simplen Heuristik.